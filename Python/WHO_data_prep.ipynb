{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparetion process\n",
    "\n",
    "> Yes, it could be done in less amount of code, but that way it's much easier to read<br>\n",
    "> Also it could be done line by line or even in Spark, but our datasets small enough to use them in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get all dirs for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../Data/WHO Datasets/Unboxed')\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are having datasets with and without metadata. So let's work only with 'DATA' marked datasets\n",
    "datalist = []\n",
    "for dirpath, dirname, filenames in os.walk(cwd):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\"Data.csv\"):\n",
    "            datalist.append(os.path.join(dirpath, file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check what is in these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series Name,Series Code,Country Name,Country Code,1960 [YR1960],1961 [YR1961],1962 [YR1962],1963 [YR1963],1964 [YR1964],1965 [YR1965],1966 [YR1966],1967 [YR1967],1968 [YR1968],1969 [YR1969],1970 [YR1970],1971 [YR1971],1972 [YR1972],1973 [YR1973],1974 [YR1974],1975 [YR1975],1976 [YR1976],1977 [YR1977],1978 [YR1978],1979 [YR1979],1980 [YR1980],1981 [YR1981],1982 [YR1982],1983 [YR1983],1984 [YR1984],1985 [YR1985],1986 [YR1986],1987 [YR1987],1988 [YR1988],1989 [YR1989],1990 [YR1990],1991 [YR1991],1992 [YR1992],1993 [YR1993],1994 [YR1994],1995 [YR1995],1996 [YR1996],1997 [YR1997],1998 [YR1998],1999 [YR1999],2000 [YR2000],2001 [YR2001],2002 [YR2002],2003 [YR2003],2004 [YR2004],2005 [YR2005],2006 [YR2006],2007 [YR2007],2008 [YR2008],2009 [YR2009],2010 [YR2010],2011 [YR2011],2012 [YR2012],2013 [YR2013],2014 [YR2014],2015 [YR2015],2016 [YR2016],2017 [YR2017],2018 [YR2018],2019 [YR2019],2020 [YR2020],2021 [YR2021]\n",
      "\n",
      "\"Birth rate, crude (per 1,000 people)\",SP.DYN.CBRT.IN,Afghanistan,AFG,50.34,50.443,50.57,50.703,50.831,50.872,50.986,51.081,51.148,51.195,51.122,51.163,51.109,51.114,51.135,51.018,50.935,50.921,50.816,50.737,50.482,50.264,50.138,50.139,50.235,50.553,50.728,50.845,50.98,51.162,51.423,51.788,51.948,52.038,52.174,52.073,51.873,51.4,50.88,50.351,49.664,48.979,48.201,47.35,46.33,45.263,44.721,43.858,41.506,41.157,40.602,39.855,40.009,39.601,39.105,38.803,37.936,37.342,36.927,36.466,36.051,..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(datalist[1], mode='r') as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because all datasets are from WHO we are can use that as a reference for all of them\n",
    "- Some datasets have more than 1 series, so for grouping will be much easier to use Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a list of countries that you're have in any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "countries = set()\n",
    "\n",
    "for dataset in datalist:\n",
    "    df = pd.read_csv(dataset)\n",
    "    df.drop(df.loc[df['Series Name'] != df['Series Name'].unique()[0]].index, axis=0, inplace=True)\n",
    "    countries.update(df['Country Code'].tolist())\n",
    "\n",
    "len(countries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a list of countries that you're have in any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_check = {}\n",
    "for country in countries:\n",
    "    country_check[country] = 'Not'\n",
    "\n",
    "for dataset in datalist:\n",
    "    df = pd.read_csv(dataset)\n",
    "    df.drop(df.loc[df['Series Name'] != df['Series Name'].unique()[0]].index, axis=0, inplace=True)\n",
    "    country_list = df['Country Code'].tolist()\n",
    "\n",
    "    for country in country_list:\n",
    "        if country_check[country] != 'Delete':\n",
    "            country_check[country] = 'Have'\n",
    "    \n",
    "    for country in country_check:\n",
    "        if country_check[country] == 'Not':\n",
    "            country_check[country] = 'Delete'\n",
    "        elif country_check[country] == 'Have':\n",
    "            country_check[country] = 'Not'\n",
    "\n",
    "countries_filtered = set()\n",
    "\n",
    "for country in country_check:\n",
    "    if country_check[country] == 'Not':\n",
    "        countries_filtered.add(country)\n",
    "\n",
    "len(countries_filtered)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Get names of countries with void lines and delete them from our countries_filtered set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_check = {}\n",
    "info_cols = ['Series Name','Series Code','Country Name','Country Code']\n",
    "\n",
    "for country in countries_filtered:\n",
    "    country_check[country] = True\n",
    "\n",
    "for dataset in datalist:\n",
    "    df = pd.read_csv(dataset, na_values='..')\n",
    "    df.drop(info_cols[0:3], axis=1, inplace=True)\n",
    "    idx = list(set(df.index) - set(df.drop('Country Code', axis=1).dropna(how='all').index))\n",
    "    for country in df.iloc[idx]['Country Code'].dropna().to_list():\n",
    "        country_check[country] = False\n",
    "    \n",
    "for country in country_check:\n",
    "    if country_check[country] == False and country in countries_filtered:\n",
    "        countries_filtered.remove(country)\n",
    "\n",
    "len(countries_filtered)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Choose a period that you're interested in\n",
    "\n",
    "> Based on the fact that each dataset can cover different periods, let's use smallest timespan in our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age) \n",
      " {'2000 [YR2000]', '2010 [YR2010]', '2015 [YR2015]', '2005 [YR2005]', '2018 [YR2018]'}\n",
      "Birth rate, crude (per 1,000 people) \n",
      " {'1980 [YR1980]', '2001 [YR2001]', '1998 [YR1998]', '1981 [YR1981]', '1974 [YR1974]', '1975 [YR1975]', '1978 [YR1978]', '2018 [YR2018]', '1973 [YR1973]', '2000 [YR2000]', '2019 [YR2019]', '1967 [YR1967]', '2015 [YR2015]', '1989 [YR1989]', '1991 [YR1991]', '2005 [YR2005]', '1992 [YR1992]', '1964 [YR1964]', '2017 [YR2017]', '2020 [YR2020]', '1994 [YR1994]', '1969 [YR1969]', '2003 [YR2003]', '2009 [YR2009]', '1999 [YR1999]', '2002 [YR2002]', '1968 [YR1968]', '2016 [YR2016]', '1971 [YR1971]', '1979 [YR1979]', '1960 [YR1960]', '1997 [YR1997]', '1995 [YR1995]', '1972 [YR1972]', '1963 [YR1963]', '2008 [YR2008]', '1977 [YR1977]', '1961 [YR1961]', '1986 [YR1986]', '1990 [YR1990]', '2013 [YR2013]', '1987 [YR1987]', '1996 [YR1996]', '2011 [YR2011]', '1966 [YR1966]', '1970 [YR1970]', '1988 [YR1988]', '1993 [YR1993]', '2007 [YR2007]', '1985 [YR1985]', '2006 [YR2006]', '2010 [YR2010]', '1982 [YR1982]', '1962 [YR1962]', '1965 [YR1965]', '1976 [YR1976]', '2014 [YR2014]', '1984 [YR1984]', '2004 [YR2004]', '1983 [YR1983]', '2012 [YR2012]'}\n",
      "Control of Corruption: Percentile Rank \n",
      " {'1998 [YR1998]', '2018 [YR2018]', '2000 [YR2000]', '2019 [YR2019]', '2015 [YR2015]', '2021 [YR2021]', '2005 [YR2005]', '2017 [YR2017]', '2020 [YR2020]', '2003 [YR2003]', '2009 [YR2009]', '2002 [YR2002]', '2016 [YR2016]', '2008 [YR2008]', '2013 [YR2013]', '1996 [YR1996]', '2011 [YR2011]', '2007 [YR2007]', '2010 [YR2010]', '2014 [YR2014]', '2004 [YR2004]', '2006 [YR2006]', '2012 [YR2012]'}\n",
      "Death rate, crude (per 1,000 people) \n",
      " {'1980 [YR1980]', '2001 [YR2001]', '1998 [YR1998]', '1981 [YR1981]', '1974 [YR1974]', '1975 [YR1975]', '1978 [YR1978]', '2018 [YR2018]', '1973 [YR1973]', '2000 [YR2000]', '2019 [YR2019]', '1967 [YR1967]', '2015 [YR2015]', '1989 [YR1989]', '1991 [YR1991]', '2005 [YR2005]', '1992 [YR1992]', '1964 [YR1964]', '2017 [YR2017]', '2020 [YR2020]', '1994 [YR1994]', '1969 [YR1969]', '2003 [YR2003]', '2009 [YR2009]', '1999 [YR1999]', '2002 [YR2002]', '1968 [YR1968]', '2016 [YR2016]', '1971 [YR1971]', '1979 [YR1979]', '1960 [YR1960]', '1997 [YR1997]', '1995 [YR1995]', '1972 [YR1972]', '1963 [YR1963]', '2008 [YR2008]', '1977 [YR1977]', '1961 [YR1961]', '1986 [YR1986]', '1990 [YR1990]', '2013 [YR2013]', '1987 [YR1987]', '1996 [YR1996]', '2011 [YR2011]', '1966 [YR1966]', '1970 [YR1970]', '1988 [YR1988]', '1993 [YR1993]', '2007 [YR2007]', '1985 [YR1985]', '2006 [YR2006]', '2010 [YR2010]', '1982 [YR1982]', '1962 [YR1962]', '1965 [YR1965]', '1976 [YR1976]', '2014 [YR2014]', '1984 [YR1984]', '2004 [YR2004]', '1983 [YR1983]', '2012 [YR2012]'}\n",
      "Domestic general government health expenditure per capita (current US$) \n",
      " {'2001 [YR2001]', '2000 [YR2000]', '2019 [YR2019]', '2015 [YR2015]', '2005 [YR2005]', '2017 [YR2017]', '2003 [YR2003]', '2009 [YR2009]', '2002 [YR2002]', '2016 [YR2016]', '2008 [YR2008]', '2013 [YR2013]', '2012 [YR2012]', '2011 [YR2011]', '2007 [YR2007]', '2010 [YR2010]', '2014 [YR2014]', '2004 [YR2004]', '2006 [YR2006]', '2018 [YR2018]'}\n",
      "GDP per capita (current US$) \n",
      " {'1980 [YR1980]', '2001 [YR2001]', '1998 [YR1998]', '1981 [YR1981]', '1974 [YR1974]', '1975 [YR1975]', '1978 [YR1978]', '2018 [YR2018]', '1973 [YR1973]', '2000 [YR2000]', '2019 [YR2019]', '1967 [YR1967]', '2015 [YR2015]', '1989 [YR1989]', '1991 [YR1991]', '2021 [YR2021]', '2005 [YR2005]', '1992 [YR1992]', '1964 [YR1964]', '2017 [YR2017]', '2020 [YR2020]', '1994 [YR1994]', '1969 [YR1969]', '2003 [YR2003]', '2009 [YR2009]', '1999 [YR1999]', '2002 [YR2002]', '1968 [YR1968]', '2016 [YR2016]', '1971 [YR1971]', '1979 [YR1979]', '1960 [YR1960]', '1997 [YR1997]', '1995 [YR1995]', '1972 [YR1972]', '1963 [YR1963]', '2008 [YR2008]', '1977 [YR1977]', '1961 [YR1961]', '1986 [YR1986]', '1990 [YR1990]', '2013 [YR2013]', '1987 [YR1987]', '1996 [YR1996]', '2011 [YR2011]', '1966 [YR1966]', '1970 [YR1970]', '1988 [YR1988]', '1993 [YR1993]', '2007 [YR2007]', '1985 [YR1985]', '2006 [YR2006]', '2010 [YR2010]', '1982 [YR1982]', '1962 [YR1962]', '1965 [YR1965]', '1976 [YR1976]', '2014 [YR2014]', '1984 [YR1984]', '2004 [YR2004]', '1983 [YR1983]', '2012 [YR2012]'}\n",
      "Income share held by highest 10% \n",
      " {'1980 [YR1980]', '2001 [YR2001]', '1998 [YR1998]', '1981 [YR1981]', '1974 [YR1974]', '1975 [YR1975]', '1978 [YR1978]', '2018 [YR2018]', '2000 [YR2000]', '2019 [YR2019]', '1967 [YR1967]', '2015 [YR2015]', '1989 [YR1989]', '1991 [YR1991]', '2021 [YR2021]', '2005 [YR2005]', '1992 [YR1992]', '2017 [YR2017]', '2020 [YR2020]', '1994 [YR1994]', '1969 [YR1969]', '2003 [YR2003]', '2009 [YR2009]', '1999 [YR1999]', '2002 [YR2002]', '2016 [YR2016]', '1971 [YR1971]', '1979 [YR1979]', '1997 [YR1997]', '1995 [YR1995]', '2008 [YR2008]', '1977 [YR1977]', '1986 [YR1986]', '1990 [YR1990]', '2013 [YR2013]', '1987 [YR1987]', '1996 [YR1996]', '2011 [YR2011]', '1988 [YR1988]', '1993 [YR1993]', '2007 [YR2007]', '1985 [YR1985]', '2006 [YR2006]', '2010 [YR2010]', '1982 [YR1982]', '2014 [YR2014]', '1984 [YR1984]', '2004 [YR2004]', '1983 [YR1983]', '2012 [YR2012]'}\n",
      "Land Surface Temperature \n",
      " {'2001 [YR2001]', '2000 [YR2000]', '2019 [YR2019]', '2015 [YR2015]', '2021 [YR2021]', '2005 [YR2005]', '2017 [YR2017]', '2020 [YR2020]', '2003 [YR2003]', '2009 [YR2009]', '2002 [YR2002]', '2016 [YR2016]', '2008 [YR2008]', '2013 [YR2013]', '2012 [YR2012]', '2011 [YR2011]', '2007 [YR2007]', '2010 [YR2010]', '2014 [YR2014]', '2004 [YR2004]', '2006 [YR2006]', '2018 [YR2018]'}\n",
      "Life expectancy at birth, female (years) \n",
      " {'1980 [YR1980]', '2001 [YR2001]', '1998 [YR1998]', '1981 [YR1981]', '1974 [YR1974]', '1975 [YR1975]', '1978 [YR1978]', '2018 [YR2018]', '1973 [YR1973]', '2000 [YR2000]', '2019 [YR2019]', '1967 [YR1967]', '2015 [YR2015]', '1989 [YR1989]', '1991 [YR1991]', '2005 [YR2005]', '1992 [YR1992]', '1964 [YR1964]', '2017 [YR2017]', '2020 [YR2020]', '1994 [YR1994]', '1969 [YR1969]', '2003 [YR2003]', '2009 [YR2009]', '1999 [YR1999]', '2002 [YR2002]', '1968 [YR1968]', '2016 [YR2016]', '1971 [YR1971]', '1979 [YR1979]', '1960 [YR1960]', '1997 [YR1997]', '1995 [YR1995]', '1972 [YR1972]', '1963 [YR1963]', '2008 [YR2008]', '1977 [YR1977]', '1961 [YR1961]', '1986 [YR1986]', '1990 [YR1990]', '2013 [YR2013]', '1987 [YR1987]', '1996 [YR1996]', '2011 [YR2011]', '1966 [YR1966]', '1970 [YR1970]', '1988 [YR1988]', '1993 [YR1993]', '2007 [YR2007]', '1985 [YR1985]', '2006 [YR2006]', '2010 [YR2010]', '1982 [YR1982]', '1962 [YR1962]', '1965 [YR1965]', '1976 [YR1976]', '2014 [YR2014]', '1984 [YR1984]', '2004 [YR2004]', '1983 [YR1983]', '2012 [YR2012]'}\n",
      "Mortality rate attributed to unsafe water, unsafe sanitation and lack of hygiene (per 100,000 population) \n",
      " {'2016 [YR2016]'}\n",
      "Social contributions (% of revenue) \n",
      " {'1980 [YR1980]', '2001 [YR2001]', '1998 [YR1998]', '1981 [YR1981]', '1974 [YR1974]', '1975 [YR1975]', '1978 [YR1978]', '2018 [YR2018]', '1973 [YR1973]', '2000 [YR2000]', '2019 [YR2019]', '2015 [YR2015]', '1989 [YR1989]', '1991 [YR1991]', '2005 [YR2005]', '1992 [YR1992]', '2017 [YR2017]', '2020 [YR2020]', '1994 [YR1994]', '2003 [YR2003]', '2009 [YR2009]', '1999 [YR1999]', '2002 [YR2002]', '2016 [YR2016]', '1979 [YR1979]', '1997 [YR1997]', '1995 [YR1995]', '1972 [YR1972]', '2008 [YR2008]', '1977 [YR1977]', '1986 [YR1986]', '1990 [YR1990]', '2013 [YR2013]', '1987 [YR1987]', '1996 [YR1996]', '2011 [YR2011]', '1988 [YR1988]', '1993 [YR1993]', '2007 [YR2007]', '1985 [YR1985]', '2006 [YR2006]', '2010 [YR2010]', '1982 [YR1982]', '2014 [YR2014]', '1976 [YR1976]', '1984 [YR1984]', '2004 [YR2004]', '1983 [YR1983]', '2012 [YR2012]'}\n",
      "Suicide mortality rate (per 100,000 population) \n",
      " {'2001 [YR2001]', '2000 [YR2000]', '2019 [YR2019]', '2015 [YR2015]', '2005 [YR2005]', '2017 [YR2017]', '2003 [YR2003]', '2009 [YR2009]', '2002 [YR2002]', '2016 [YR2016]', '2008 [YR2008]', '2013 [YR2013]', '2012 [YR2012]', '2011 [YR2011]', '2007 [YR2007]', '2010 [YR2010]', '2014 [YR2014]', '2004 [YR2004]', '2006 [YR2006]', '2018 [YR2018]'}\n",
      "Voice and Accountability: Percentile Rank \n",
      " {'1998 [YR1998]', '2018 [YR2018]', '2000 [YR2000]', '2019 [YR2019]', '2015 [YR2015]', '2021 [YR2021]', '2005 [YR2005]', '2017 [YR2017]', '2020 [YR2020]', '2003 [YR2003]', '2009 [YR2009]', '2002 [YR2002]', '2016 [YR2016]', '2008 [YR2008]', '2013 [YR2013]', '1996 [YR1996]', '2011 [YR2011]', '2007 [YR2007]', '2010 [YR2010]', '2014 [YR2014]', '2004 [YR2004]', '2006 [YR2006]', '2012 [YR2012]'}\n"
     ]
    }
   ],
   "source": [
    "period = {}\n",
    "\n",
    "for dataset in datalist:\n",
    "    df = pd.read_csv(dataset, na_values='..')\n",
    "    years = set(df.drop(info_cols, axis=1).dropna(how='all',axis=1).columns)\n",
    "    print(df['Series Name'][0],'\\n', years)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see - we will have a very bad time with our datasets in some cases. So we should forget about datasets:<br>\n",
    "`Mortality rate attributed to unsafe water, unsafe sanitation and lack of hygiene`<br>\n",
    "`Total alcohol consumption per capita`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datalist[0]\n",
    "del datalist[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2019\n"
     ]
    }
   ],
   "source": [
    "period = {}\n",
    "years_min = 0\n",
    "years_max = 9999\n",
    "\n",
    "for dataset in datalist:\n",
    "    df = pd.read_csv(dataset, na_values='..')\n",
    "    years = set(df.drop(info_cols, axis=1).dropna(how='all',axis=1).columns)\n",
    "    if int(min(years)[0:4]) > years_min:\n",
    "        years_min = int(min(years)[0:4])\n",
    "    if int(max(years)[0:4]) < years_max:\n",
    "        years_max = int(max(years)[0:4])\n",
    "\n",
    "print(years_min, years_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will increase that timespan to 20 years. 1999-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1960 [YR1960]', '1961 [YR1961]', '1962 [YR1962]', '1963 [YR1963]',\n",
       "       '1964 [YR1964]', '1965 [YR1965]', '1966 [YR1966]', '1967 [YR1967]',\n",
       "       '1968 [YR1968]', '1969 [YR1969]', '1970 [YR1970]', '1971 [YR1971]',\n",
       "       '1972 [YR1972]', '1973 [YR1973]', '1974 [YR1974]', '1975 [YR1975]',\n",
       "       '1976 [YR1976]', '1977 [YR1977]', '1978 [YR1978]', '1979 [YR1979]',\n",
       "       '1980 [YR1980]', '1981 [YR1981]', '1982 [YR1982]', '1983 [YR1983]',\n",
       "       '1984 [YR1984]', '1985 [YR1985]', '1986 [YR1986]', '1987 [YR1987]',\n",
       "       '1988 [YR1988]', '1989 [YR1989]', '1990 [YR1990]', '1991 [YR1991]',\n",
       "       '1992 [YR1992]', '1993 [YR1993]', '1994 [YR1994]', '1995 [YR1995]',\n",
       "       '1996 [YR1996]', '1997 [YR1997]', '1998 [YR1998]', '1999 [YR1999]',\n",
       "       '2000 [YR2000]', '2001 [YR2001]', '2002 [YR2002]', '2003 [YR2003]',\n",
       "       '2004 [YR2004]', '2005 [YR2005]', '2006 [YR2006]', '2007 [YR2007]',\n",
       "       '2008 [YR2008]', '2009 [YR2009]', '2010 [YR2010]', '2011 [YR2011]',\n",
       "       '2012 [YR2012]', '2013 [YR2013]', '2014 [YR2014]', '2015 [YR2015]',\n",
       "       '2016 [YR2016]', '2017 [YR2017]', '2018 [YR2018]', '2019 [YR2019]',\n",
       "       '2020 [YR2020]', '2021 [YR2021]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Savilg it as a set of columns\n",
    "df = pd.read_csv(datalist[0], na_values='..')\n",
    "years_col_list = df.drop(info_cols, axis=1).columns\n",
    "years_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will check first and last position. We'll work with everything inbetween\n",
    "years_col_list = [\n",
    "    '2000 [YR2000]', '2019 [YR2019]'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_col_list_full = [\n",
    "    '2000 [YR2000]', '2001 [YR2001]', '2002 [YR2002]', '2003 [YR2003]',\n",
    "    '2004 [YR2004]', '2005 [YR2005]', '2006 [YR2006]', '2007 [YR2007]',\n",
    "    '2008 [YR2008]', '2009 [YR2009]', '2010 [YR2010]', '2011 [YR2011]',\n",
    "    '2012 [YR2012]', '2013 [YR2013]', '2014 [YR2014]', '2015 [YR2015]',\n",
    "    '2016 [YR2016]', '2017 [YR2017]', '2018 [YR2018]', '2019 [YR2019]'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Delete all countries that have smaller observation period (SHOuLD BE REWRITTEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not: 20\n",
      "Delete: 119\n"
     ]
    }
   ],
   "source": [
    "# For check if country is inside our period\n",
    "countries_check = {}\n",
    "for country in countries_filtered:\n",
    "    countries_check[country] = 'Not'\n",
    "\n",
    "\n",
    "for dataset in datalist:\n",
    "    df = pd.read_csv(dataset, na_values='..')\n",
    "    df_years = df.loc[df['Series Name'][0] == df['Series Name']].drop(info_cols[0:3], axis=1)\n",
    "\n",
    "    df_years[years_col_list + ['Country Code']]\n",
    "    \n",
    "    for country in df_years[years_col_list + ['Country Code']].dropna(how='any')['Country Code']:\n",
    "        if country in countries_check and countries_check[country] != 'Delete':\n",
    "          countries_check[country] = 'Have'\n",
    "    \n",
    "    for country in countries_check:\n",
    "        if countries_check[country] == 'Not':\n",
    "            countries_check[country] = 'Delete'\n",
    "        elif countries_check[country] == 'Have':\n",
    "            countries_check[country] = 'Not'\n",
    "\n",
    "b=[i[1] for i in countries_check.items()]\n",
    "\n",
    "for k in list(set(b)):\n",
    "    print(\"{0}: {1}\".format(k, b.count(k)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will use 20 countries. Let's record list of their country codes in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for country in countries_check:\n",
    "    if countries_check[country] == 'Delete' and country in countries_filtered:\n",
    "        countries_filtered.remove(country)\n",
    "\n",
    "len(countries_filtered)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Check for data gaps in your data and fill them if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datalist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets should be checked separatelty, one by one, each has it's own specific<br>\n",
    "Since it will be a lot of datasets, here as functions i will create repeatetive tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Code</th>\n",
       "      <th>1996 [YR1996]</th>\n",
       "      <th>1998 [YR1998]</th>\n",
       "      <th>2000 [YR2000]</th>\n",
       "      <th>2002 [YR2002]</th>\n",
       "      <th>2003 [YR2003]</th>\n",
       "      <th>2004 [YR2004]</th>\n",
       "      <th>2005 [YR2005]</th>\n",
       "      <th>2006 [YR2006]</th>\n",
       "      <th>2007 [YR2007]</th>\n",
       "      <th>...</th>\n",
       "      <th>2012 [YR2012]</th>\n",
       "      <th>2013 [YR2013]</th>\n",
       "      <th>2014 [YR2014]</th>\n",
       "      <th>2015 [YR2015]</th>\n",
       "      <th>2016 [YR2016]</th>\n",
       "      <th>2017 [YR2017]</th>\n",
       "      <th>2018 [YR2018]</th>\n",
       "      <th>2019 [YR2019]</th>\n",
       "      <th>2020 [YR2020]</th>\n",
       "      <th>2021 [YR2021]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUS</td>\n",
       "      <td>43.5</td>\n",
       "      <td>36.815922</td>\n",
       "      <td>37.810944</td>\n",
       "      <td>36.318409</td>\n",
       "      <td>32.338310</td>\n",
       "      <td>30.769230</td>\n",
       "      <td>27.403847</td>\n",
       "      <td>22.115385</td>\n",
       "      <td>22.596153</td>\n",
       "      <td>...</td>\n",
       "      <td>19.248827</td>\n",
       "      <td>18.779343</td>\n",
       "      <td>20.689655</td>\n",
       "      <td>20.197044</td>\n",
       "      <td>17.733990</td>\n",
       "      <td>18.719212</td>\n",
       "      <td>18.840580</td>\n",
       "      <td>17.874395</td>\n",
       "      <td>20.289856</td>\n",
       "      <td>19.806763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>9.452736</td>\n",
       "      <td>14.427860</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>14.903846</td>\n",
       "      <td>17.788462</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.084507</td>\n",
       "      <td>14.553990</td>\n",
       "      <td>16.256157</td>\n",
       "      <td>18.719212</td>\n",
       "      <td>20.689655</td>\n",
       "      <td>22.167488</td>\n",
       "      <td>20.289856</td>\n",
       "      <td>21.256039</td>\n",
       "      <td>19.806763</td>\n",
       "      <td>7.246377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>29.5</td>\n",
       "      <td>38.805969</td>\n",
       "      <td>41.293533</td>\n",
       "      <td>48.258705</td>\n",
       "      <td>50.248756</td>\n",
       "      <td>49.038460</td>\n",
       "      <td>51.442307</td>\n",
       "      <td>49.038460</td>\n",
       "      <td>51.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>50.704224</td>\n",
       "      <td>51.173710</td>\n",
       "      <td>50.246304</td>\n",
       "      <td>52.709358</td>\n",
       "      <td>52.216747</td>\n",
       "      <td>54.187191</td>\n",
       "      <td>52.657005</td>\n",
       "      <td>52.173912</td>\n",
       "      <td>51.207729</td>\n",
       "      <td>50.241547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DZA</td>\n",
       "      <td>14.5</td>\n",
       "      <td>12.437811</td>\n",
       "      <td>14.427860</td>\n",
       "      <td>18.905472</td>\n",
       "      <td>18.905472</td>\n",
       "      <td>23.557692</td>\n",
       "      <td>25.480770</td>\n",
       "      <td>22.596153</td>\n",
       "      <td>20.192308</td>\n",
       "      <td>...</td>\n",
       "      <td>22.535212</td>\n",
       "      <td>23.943663</td>\n",
       "      <td>25.123152</td>\n",
       "      <td>24.630543</td>\n",
       "      <td>23.645321</td>\n",
       "      <td>23.152710</td>\n",
       "      <td>21.256039</td>\n",
       "      <td>19.806763</td>\n",
       "      <td>19.323671</td>\n",
       "      <td>20.772947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.423080</td>\n",
       "      <td>70.673080</td>\n",
       "      <td>65.384613</td>\n",
       "      <td>78.365387</td>\n",
       "      <td>...</td>\n",
       "      <td>80.751175</td>\n",
       "      <td>81.220657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.169083</td>\n",
       "      <td>92.753624</td>\n",
       "      <td>81.642509</td>\n",
       "      <td>75.845413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>VIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.038460</td>\n",
       "      <td>85.576920</td>\n",
       "      <td>72.115387</td>\n",
       "      <td>70.673080</td>\n",
       "      <td>...</td>\n",
       "      <td>73.239433</td>\n",
       "      <td>72.300468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>PSE</td>\n",
       "      <td>24.5</td>\n",
       "      <td>28.855721</td>\n",
       "      <td>25.870647</td>\n",
       "      <td>24.378109</td>\n",
       "      <td>24.378109</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>33.173077</td>\n",
       "      <td>28.365385</td>\n",
       "      <td>...</td>\n",
       "      <td>20.657276</td>\n",
       "      <td>22.535212</td>\n",
       "      <td>22.660099</td>\n",
       "      <td>21.674877</td>\n",
       "      <td>18.719212</td>\n",
       "      <td>21.674877</td>\n",
       "      <td>22.222221</td>\n",
       "      <td>20.772947</td>\n",
       "      <td>17.391304</td>\n",
       "      <td>19.323671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>YEM</td>\n",
       "      <td>27.5</td>\n",
       "      <td>26.368158</td>\n",
       "      <td>24.378109</td>\n",
       "      <td>14.925373</td>\n",
       "      <td>23.880596</td>\n",
       "      <td>20.192308</td>\n",
       "      <td>17.307692</td>\n",
       "      <td>16.346153</td>\n",
       "      <td>16.346153</td>\n",
       "      <td>...</td>\n",
       "      <td>9.389671</td>\n",
       "      <td>11.737089</td>\n",
       "      <td>11.822660</td>\n",
       "      <td>7.389163</td>\n",
       "      <td>5.418719</td>\n",
       "      <td>5.911330</td>\n",
       "      <td>3.864734</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>3.864734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34.825871</td>\n",
       "      <td>35.820896</td>\n",
       "      <td>41.293533</td>\n",
       "      <td>38.805969</td>\n",
       "      <td>34.615383</td>\n",
       "      <td>34.615383</td>\n",
       "      <td>39.423077</td>\n",
       "      <td>39.903847</td>\n",
       "      <td>...</td>\n",
       "      <td>44.131454</td>\n",
       "      <td>44.131454</td>\n",
       "      <td>44.334976</td>\n",
       "      <td>45.812809</td>\n",
       "      <td>36.453201</td>\n",
       "      <td>36.453201</td>\n",
       "      <td>35.265701</td>\n",
       "      <td>36.231884</td>\n",
       "      <td>34.782608</td>\n",
       "      <td>35.265701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>30.5</td>\n",
       "      <td>25.870647</td>\n",
       "      <td>15.920398</td>\n",
       "      <td>10.945273</td>\n",
       "      <td>9.950249</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>5.288462</td>\n",
       "      <td>7.211538</td>\n",
       "      <td>7.211538</td>\n",
       "      <td>...</td>\n",
       "      <td>7.511737</td>\n",
       "      <td>9.859155</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>15.763547</td>\n",
       "      <td>14.778325</td>\n",
       "      <td>14.778325</td>\n",
       "      <td>16.908213</td>\n",
       "      <td>16.425121</td>\n",
       "      <td>17.874395</td>\n",
       "      <td>18.357489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country Code  1996 [YR1996]  1998 [YR1998]  2000 [YR2000]  2002 [YR2002]  \\\n",
       "0            RUS           43.5      36.815922      37.810944      36.318409   \n",
       "1            AFG            1.0       0.497512       0.995025       9.452736   \n",
       "2            ALB           29.5      38.805969      41.293533      48.258705   \n",
       "3            DZA           14.5      12.437811      14.427860      18.905472   \n",
       "4            ASM            NaN            NaN            NaN            NaN   \n",
       "..           ...            ...            ...            ...            ...   \n",
       "209          VIR            NaN            NaN            NaN            NaN   \n",
       "210          PSE           24.5      28.855721      25.870647      24.378109   \n",
       "211          YEM           27.5      26.368158      24.378109      14.925373   \n",
       "212          ZMB           38.0      34.825871      35.820896      41.293533   \n",
       "213          ZWE           30.5      25.870647      15.920398      10.945273   \n",
       "\n",
       "     2003 [YR2003]  2004 [YR2004]  2005 [YR2005]  2006 [YR2006]  \\\n",
       "0        32.338310      30.769230      27.403847      22.115385   \n",
       "1        14.427860      15.384615      14.903846      17.788462   \n",
       "2        50.248756      49.038460      51.442307      49.038460   \n",
       "3        18.905472      23.557692      25.480770      22.596153   \n",
       "4              NaN      64.423080      70.673080      65.384613   \n",
       "..             ...            ...            ...            ...   \n",
       "209            NaN      74.038460      85.576920      72.115387   \n",
       "210      24.378109      26.923077      26.923077      33.173077   \n",
       "211      23.880596      20.192308      17.307692      16.346153   \n",
       "212      38.805969      34.615383      34.615383      39.423077   \n",
       "213       9.950249       6.250000       5.288462       7.211538   \n",
       "\n",
       "     2007 [YR2007]  ...  2012 [YR2012]  2013 [YR2013]  2014 [YR2014]  \\\n",
       "0        22.596153  ...      19.248827      18.779343      20.689655   \n",
       "1        18.750000  ...      14.084507      14.553990      16.256157   \n",
       "2        51.923077  ...      50.704224      51.173710      50.246304   \n",
       "3        20.192308  ...      22.535212      23.943663      25.123152   \n",
       "4        78.365387  ...      80.751175      81.220657            NaN   \n",
       "..             ...  ...            ...            ...            ...   \n",
       "209      70.673080  ...      73.239433      72.300468            NaN   \n",
       "210      28.365385  ...      20.657276      22.535212      22.660099   \n",
       "211      16.346153  ...       9.389671      11.737089      11.822660   \n",
       "212      39.903847  ...      44.131454      44.131454      44.334976   \n",
       "213       7.211538  ...       7.511737       9.859155      13.793103   \n",
       "\n",
       "     2015 [YR2015]  2016 [YR2016]  2017 [YR2017]  2018 [YR2018]  \\\n",
       "0        20.197044      17.733990      18.719212      18.840580   \n",
       "1        18.719212      20.689655      22.167488      20.289856   \n",
       "2        52.709358      52.216747      54.187191      52.657005   \n",
       "3        24.630543      23.645321      23.152710      21.256039   \n",
       "4              NaN            NaN            NaN      95.169083   \n",
       "..             ...            ...            ...            ...   \n",
       "209            NaN            NaN            NaN            NaN   \n",
       "210      21.674877      18.719212      21.674877      22.222221   \n",
       "211       7.389163       5.418719       5.911330       3.864734   \n",
       "212      45.812809      36.453201      36.453201      35.265701   \n",
       "213      15.763547      14.778325      14.778325      16.908213   \n",
       "\n",
       "     2019 [YR2019]  2020 [YR2020]  2021 [YR2021]  \n",
       "0        17.874395      20.289856      19.806763  \n",
       "1        21.256039      19.806763       7.246377  \n",
       "2        52.173912      51.207729      50.241547  \n",
       "3        19.806763      19.323671      20.772947  \n",
       "4        92.753624      81.642509      75.845413  \n",
       "..             ...            ...            ...  \n",
       "209            NaN            NaN            NaN  \n",
       "210      20.772947      17.391304      19.323671  \n",
       "211       4.347826       4.347826       3.864734  \n",
       "212      36.231884      34.782608      35.265701  \n",
       "213      16.425121      17.874395      18.357489  \n",
       "\n",
       "[214 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Series Name'][0] == df['Series Name']].drop(info_cols[0:3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it will be a lot of datasets, here as functions i will create a main repeatetive task\n",
    "def who_dataset_check(dfloc, yearlist=[], countries=[], infcol=[]):\n",
    "    df = pd.read_csv(dfloc, na_values=\"..\")\n",
    "    df = df.loc[df['Country Code'].isin(countries)]\n",
    "    print('>', df['Series Name'].reset_index(drop=True)[0])\n",
    "\n",
    "    # We will assume based on the data collection process that if table has more than 1 series, then gaps in them are positioned in the same places\n",
    "    # It is based on the fact that each table is from the same research process. Different series is only separation by gender or class\n",
    "    df_years = df.loc[df['Series Name'].reset_index(drop=True)[0] == df['Series Name']].drop(info_cols[0:3], axis=1)\n",
    "\n",
    "    # For check if all years are in our dataset\n",
    "    years_col_list_check = {}\n",
    "    for year in yearlist:\n",
    "        years_col_list_check[year] = False\n",
    "\n",
    "    for col in df_years.columns.drop('Country Code'):\n",
    "        if col in yearlist:\n",
    "            years_col_list_check[col] = True\n",
    "\n",
    "    # That list is needed for the column selection. If we're don't have any, we will get an error\n",
    "    # I'm sure that there is another way, but this is easier\n",
    "    temp_year_list = []\n",
    "    for year in years_col_list_check:\n",
    "        if years_col_list_check[year] == True:\n",
    "            temp_year_list.append(year)\n",
    "        else:\n",
    "            print(\"Table doesn't have column {0}\".format(year))\n",
    "\n",
    "    #This is check if our dataset even has a null values\n",
    "    na_all_check = False\n",
    "\n",
    "    for country in df_years['Country Code']:\n",
    "        row_check = False\n",
    "        na_col_list = []\n",
    "        for col in temp_year_list:\n",
    "            row_check = df_years.loc[df['Country Code'] == country][col].isna().bool() or row_check\n",
    "            if df_years.loc[df['Country Code'] == country][col].isna().bool() == True:\n",
    "                na_col_list.append(col)\n",
    "        if row_check == True:\n",
    "            print('Country {0} has an null values in the next columns: {1}'.format(country, na_col_list))\n",
    "            na_all_check = True\n",
    "\n",
    "    # If row_check never triggered\n",
    "    if na_all_check == False:\n",
    "        print('Countries have no NaN values except missing columns')\n",
    "\n",
    "    print()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0\n",
      "> Birth rate, crude (per 1,000 people)\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 1\n",
      "> Control of Corruption: Percentile Rank\n",
      "Table doesn't have column 2001 [YR2001]\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 2\n",
      "> Death rate, crude (per 1,000 people)\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 3\n",
      "> Domestic general government health expenditure per capita (current US$)\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 4\n",
      "> GDP per capita (current US$)\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 5\n",
      "> Income share held by highest 10%\n",
      "Country ARG has an null values in the next columns: ['2015 [YR2015]']\n",
      "Country AUT has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country BEL has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country COL has an null values in the next columns: ['2006 [YR2006]', '2007 [YR2007]']\n",
      "Country DNK has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country FIN has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country GRC has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country LUX has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country NOR has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country SWE has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]']\n",
      "Country THA has an null values in the next columns: ['2001 [YR2001]', '2003 [YR2003]', '2005 [YR2005]']\n",
      "\n",
      "Dataset 6\n",
      "> Land Surface Temperature\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 7\n",
      "> Life expectancy at birth, female (years)\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 8\n",
      "> Social contributions (% of revenue)\n",
      "Country COL has an null values in the next columns: ['2001 [YR2001]', '2002 [YR2002]', '2004 [YR2004]', '2005 [YR2005]', '2006 [YR2006]', '2007 [YR2007]']\n",
      "\n",
      "Dataset 9\n",
      "> Suicide mortality rate (per 100,000 population)\n",
      "Countries have no NaN values except missing columns\n",
      "\n",
      "Dataset 10\n",
      "> Voice and Accountability: Percentile Rank\n",
      "Table doesn't have column 2001 [YR2001]\n",
      "Countries have no NaN values except missing columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datalist)):\n",
    "    print('Dataset', i)\n",
    "    who_dataset_check(datalist[i], yearlist=years_col_list_full, countries=countries_filtered, infcol=info_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Save in the most comfortable way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
